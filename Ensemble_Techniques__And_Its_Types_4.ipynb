{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Build a random forest classifier to predict the risk of heart disease based on a dataset of patient\n",
        "information. The dataset contains 303 instances with 14 features, including age, sex, chest pain type,\n",
        "resting blood pressure, serum cholesterol, and maximum heart rate achieved.\n",
        "\n",
        "\n",
        "Dataset link: https://drive.google.com/file/d/1bGoIE4Z2kG5nyh-fGZAJ7LH0ki3UfmSJ/view?\n",
        "usp=share_link\n",
        "\n",
        "\n",
        "\n",
        "Q1. Preprocess the dataset by handling missing values, encoding categorical variables, and scaling the\n",
        "numerical features if necessary.\n",
        "\n",
        "Q2. Split the dataset into a training set (70%) and a test set (30%).\n",
        "\n",
        "Q3. Train a random forest classifier on the training set using 100 trees and a maximum depth of 10 for each\n",
        "tree. Use the default values for other hyperparameters.\n",
        "\n",
        "Q4. Evaluate the performance of the model on the test set using accuracy, precision, recall, and F1 score.\n",
        "\n",
        "Q5. Use the feature importance scores to identify the top 5 most important features in predicting heart\n",
        "disease risk. Visualise the feature importances using a bar chart.\n",
        "\n",
        "Q6. Tune the hyperparameters of the random forest classifier using grid search or random search. Try\n",
        "different values of the number of trees, maximum depth, minimum samples split, and minimum samples\n",
        "leaf. Use 5-fold cross-validation to evaluate the performance of each set of hyperparameters.\n",
        "\n",
        "Q7. Report the best set of hyperparameters found by the search and the corresponding performance\n",
        "metrics. Compare the performance of the tuned model with the default model.\n",
        "\n",
        "Q8. Interpret the model by analysing the decision boundaries of the random forest classifier. Plot the\n",
        "decision boundaries on a scatter plot of two of the most important features. Discuss the insights and\n",
        "limitations of the model for predicting heart disease risk."
      ],
      "metadata": {
        "id": "MGM4S6F4SWnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "url = \"https://drive.google.com/file/d/1bGoIE4Z2kG5nyh-fGZAJ7LH0ki3UfmSJ/view?usp=sharing\"\n",
        "path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]\n",
        "data = pd.read_csv(path)\n",
        "\n",
        "# Q1. Preprocess the dataset\n",
        "# Handling missing values (imputing with mean)\n",
        "data.fillna(data.mean(), inplace=True)\n",
        "\n",
        "# Encoding categorical variables (if any, you need to check the dataset)\n",
        "# Since the dataset doesn't have categorical variables, encoding isn't necessary.\n",
        "\n",
        "# Scaling numerical features (if necessary, check if features need scaling)\n",
        "# In this case, scaling might not be necessary since RandomForest is not sensitive to feature scaling.\n",
        "\n",
        "# Q2. Split the dataset into training and test sets\n",
        "X = data.drop('target', axis=1)\n",
        "y = data['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Q3. Train a random forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Q4. Evaluate the performance of the model\n",
        "y_pred = rf_classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "\n",
        "# Q5. Identify top 5 most important features\n",
        "feature_importances = rf_classifier.feature_importances_\n",
        "sorted_indices = np.argsort(feature_importances)[::-1]\n",
        "top_5_indices = sorted_indices[:5]\n",
        "top_5_features = X.columns[top_5_indices]\n",
        "print(\"Top 5 Most Important Features:\")\n",
        "for feature in top_5_features:\n",
        "    print(feature)\n",
        "\n",
        "# Visualize feature importances\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(range(len(top_5_features)), feature_importances[top_5_indices], tick_label=top_5_features)\n",
        "plt.title('Top 5 Most Important Features')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Importance Score')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "# Q6. Tune hyperparameters using GridSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [5, 10, 15],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Q7. Report best hyperparameters and corresponding performance metrics\n",
        "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "best_rf_classifier = grid_search.best_estimator_\n",
        "y_pred_tuned = best_rf_classifier.predict(X_test)\n",
        "accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
        "precision_tuned = precision_score(y_test, y_pred_tuned)\n",
        "recall_tuned = recall_score(y_test, y_pred_tuned)\n",
        "f1_tuned = f1_score(y_test, y_pred_tuned)\n",
        "print(\"Tuned Model Performance:\")\n",
        "print(\"Accuracy:\", accuracy_tuned)\n",
        "print(\"Precision:\", precision_tuned)\n",
        "print(\"Recall:\", recall_tuned)\n",
        "print(\"F1 Score:\", f1_tuned)\n",
        "\n",
        "# Q8. Visualize decision boundaries\n",
        "# Since the dataset has multiple features, it's challenging to visualize decision boundaries in 14 dimensions.\n",
        "# For the sake of simplicity, let's consider only two most important features.\n",
        "# Let's choose 'age' and 'maximum heart rate achieved' for visualization.\n",
        "\n",
        "# Select two most important features\n",
        "feature1, feature2 = top_5_features[:2]\n",
        "\n",
        "# Select corresponding columns from training data\n",
        "X_train_subset = X_train[[feature1, feature2]]\n",
        "\n",
        "# Train RandomForestClassifier on these two features\n",
        "rf_classifier_subset = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "rf_classifier_subset.fit(X_train_subset, y_train)\n",
        "\n",
        "# Plot decision boundaries\n",
        "plt.figure(figsize=(10, 6))\n",
        "x_min, x_max = X_train_subset[feature1].min() - 1, X_train_subset[feature1].max() + 1\n",
        "y_min, y_max = X_train_subset[feature2].min() - 1, X_train_subset[feature2].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
        "                     np.arange(y_min, y_max, 0.1))\n",
        "Z = rf_classifier_subset.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "plt.contourf(xx, yy, Z, alpha=0.4)\n",
        "plt.scatter(X_train_subset[feature1], X_train_subset[feature2], c=y_train, s=20, edgecolor='k')\n",
        "plt.xlabel(feature1)\n",
        "plt.ylabel(feature2)\n",
        "plt.title('Decision Boundaries of Random Forest Classifier')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-LbnBHUVS7hM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}