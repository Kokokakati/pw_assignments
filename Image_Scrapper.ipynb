{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Go to this given URL and solve the following questions\n",
        "URL: https://www.youtube.com/@PW-Foundation/videos\n",
        "\n",
        "Q1. Write a python program to extract the video URL of the first five videos.\n",
        "\n",
        "Q2. Write a python program to extract the URL of the video thumbnails of the first five videos.\n",
        "\n",
        "Q3. Write a python program to extract the title of the first five videos.\n",
        "\n",
        "Q4. Write a python program to extract the number of views of the first five videos.\n",
        "\n",
        "Q5. Write a python program to extract the time of posting of video for the first five videos.\n",
        "\n",
        "Note: Save all the data scraped in the above questions in a CSV file."
      ],
      "metadata": {
        "id": "X-y8yMlpWABI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "video_urls = []\n",
        "for link in soup.find_all(\"a\", {\"id\": \"video-title\"}):\n",
        "    video_urls.append(\"https://www.youtube.com\" + link[\"href\"])\n",
        "\n",
        "# Extract only the first five video URLs\n",
        "first_five_video_urls = video_urls[:5]\n",
        "print(first_five_video_urls)\n"
      ],
      "metadata": {
        "id": "S1ZY7VFCWIH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2\n",
        "thumbnail_urls = []\n",
        "for thumbnail in soup.find_all(\"img\", {\"class\": \"style-scope ytd-thumbnail\"}):\n",
        "    thumbnail_urls.append(thumbnail[\"src\"])\n",
        "\n",
        "# Extract only the thumbnail URLs of the first five videos\n",
        "first_five_thumbnail_urls = thumbnail_urls[:5]\n",
        "print(first_five_thumbnail_urls)\n"
      ],
      "metadata": {
        "id": "uUDrEmbZWNi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3\n",
        "titles = []\n",
        "for title in soup.find_all(\"a\", {\"id\": \"video-title\"}):\n",
        "    titles.append(title.text.strip())\n",
        "\n",
        "# Extract only the titles of the first five videos\n",
        "first_five_titles = titles[:5]\n",
        "print(first_five_titles)\n"
      ],
      "metadata": {
        "id": "UKNv6mCcWQRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4\n",
        "views = []\n",
        "for view in soup.find_all(\"span\", {\"class\": \"style-scope ytd-grid-video-renderer\"}):\n",
        "    if \"views\" in view.text.strip():\n",
        "        views.append(view.text.strip())\n",
        "\n",
        "# Extract only the number of views of the first five videos\n",
        "first_five_views = views[:5]\n",
        "print(first_five_views)\n"
      ],
      "metadata": {
        "id": "AvwVNFvrWSkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5\n",
        "times = []\n",
        "for time in soup.find_all(\"yt-formatted-string\", {\"class\": \"style-scope ytd-grid-video-renderer\"}):\n",
        "    if \"ago\" in time.text.strip():\n",
        "        times.append(time.text.strip())\n",
        "\n",
        "# Extract only the posting times of the first five videos\n",
        "first_five_times = times[:5]\n",
        "print(first_five_times)\n"
      ],
      "metadata": {
        "id": "MjglSAHyWU1Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}