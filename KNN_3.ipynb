{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. Write a Python code to implement the KNN classifier algorithm on load_iris dataset in\n",
        "sklearn.datasets.\n",
        "\n",
        "Q2. Write a Python code to implement the KNN regressor algorithm on load_boston dataset in\n",
        "sklearn.datasets.\n",
        "\n",
        "Q3. Write a Python code snippet to find the optimal value of K for the KNN classifier algorithm using\n",
        "cross-validation on load_iris dataset in sklearn.datasets.\n",
        "\n",
        "Q4. Implement the KNN regressor algorithm with feature scaling on load_boston dataset in\n",
        "sklearn.datasets.\n",
        "\n",
        "Q5. Write a Python code snippet to implement the KNN classifier algorithm with weighted voting on\n",
        "load_iris dataset in sklearn.datasets.\n",
        "\n",
        "Q6. Implement a function to standardise the features before applying KNN classifier.\n",
        "\n",
        "Q7. Write a Python function to calculate the euclidean distance between two points.\n",
        "\n",
        "Q8. Write a Python function to calculate the manhattan distance between two points."
      ],
      "metadata": {
        "id": "gLIItAcz-MCb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5C8gePCO-Q-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "1.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a KNN classifier with k=3\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Fit the classifier to the training data\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predict the class labels for the test set\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance (e.g., using accuracy)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "McBh8zWM-WS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "2.\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "# Load the Boston Housing dataset\n",
        "boston = load_boston()\n",
        "X = boston.data\n",
        "y = boston.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a KNN regressor with k=5\n",
        "knn = KNeighborsRegressor(n_neighbors=5)\n",
        "\n",
        "# Fit the regressor to the training data\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predict the target values for the test set\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance (e.g., using mean squared error)\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n"
      ],
      "metadata": {
        "id": "3c3iQpJH-X3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "3.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Create a KNN classifier\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "# Perform cross-validation to find the optimal K\n",
        "k_values = list(range(1, 31))\n",
        "cv_scores = []\n",
        "for k in k_values:\n",
        "    knn.n_neighbors = k\n",
        "    scores = cross_val_score(knn, X, y, cv=5, scoring='accuracy')\n",
        "    cv_scores.append(scores.mean())\n",
        "\n",
        "# Find the optimal K with the highest cross-validation score\n",
        "optimal_k = k_values[cv_scores.index(max(cv_scores))]\n",
        "print(\"Optimal K:\", optimal_k)"
      ],
      "metadata": {
        "id": "kNCS-U_E-kfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "4.\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the Boston Housing dataset\n",
        "boston = load_boston()\n",
        "X = boston.data\n",
        "y = boston.target\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the standardized dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a KNN regressor with k=5\n",
        "knn = KNeighborsRegressor(n_neighbors=5)\n",
        "\n",
        "# Fit the regressor to the training data\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predict the target values for the test set\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance (e.g., using mean squared error)\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n"
      ],
      "metadata": {
        "id": "hp54gJ9H-lee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "5.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a KNN classifier with k=3 and weights='distance'\n",
        "knn = KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
        "\n",
        "# Fit the classifier to the training data\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predict the class labels for the test set\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance (e.g., using accuracy)\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "qm0vcEfl-pF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "6.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def standardize_features(X_train, X_test):\n",
        "    scaler = StandardScaler()\n",
        "    X_train_std = scaler.fit_transform(X_train)\n",
        "    X_test_std = scaler.transform(X_test)\n",
        "    return X_train_std, X_test_std\n",
        "\n",
        "# Usage:\n",
        "# X_train_std, X_test_std = standardize_features(X_train, X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "cHvir4FS-sAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "7.\n",
        "import numpy as np\n",
        "\n",
        "def euclidean_distance(point1, point2):\n",
        "    return np.sqrt(np.sum((point1 - point2) ** 2))\n",
        "\n",
        "# Usage:\n",
        "# dist = euclidean_distance(point1, point2)\n"
      ],
      "metadata": {
        "id": "jg2vfkvV-y6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "8.\n",
        "import numpy as np\n",
        "\n",
        "def manhattan_distance(point1, point2):\n",
        "    return np.sum(np.abs(point1 - point2))\n",
        "\n",
        "# Usage:\n",
        "# dist = manhattan_distance(point1, point2)\n"
      ],
      "metadata": {
        "id": "W8wH-Hym-1Nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6cq6gzY5-ezu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}