{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is the Filter method in feature selection, and how does it work?\n",
        "\n",
        "Q2. How does the Wrapper method differ from the Filter method in feature selection?\n",
        "\n",
        "Q3. What are some common techniques used in Embedded feature selection methods?\n",
        "\n",
        "Q4. What are some drawbacks of using the Filter method for feature selection?\n",
        "\n",
        "Q5. In which situations would you prefer using the Filter method over the Wrapper method for feature\n",
        "selection?\n",
        "\n",
        "Q6. In a telecom company, you are working on a project to develop a predictive model for customer churn.\n",
        "You are unsure of which features to include in the model because the dataset contains several different\n",
        "ones. Describe how you would choose the most pertinent attributes for the model using the Filter Method.\n",
        "\n",
        "Q7. You are working on a project to predict the outcome of a soccer match. You have a large dataset with\n",
        "many features, including player statistics and team rankings. Explain how you would use the Embedded\n",
        "method to select the most relevant features for the model.\n",
        "\n",
        "Q8. You are working on a project to predict the price of a house based on its features, such as size, location,\n",
        "and age. You have a limited number of features, and you want to ensure that you select the most important\n",
        "ones for the model. Explain how you would use the Wrapper method to select the best set of features for the\n",
        "predictor."
      ],
      "metadata": {
        "id": "vAtt8YYNmW8Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  *********************************************************"
      ],
      "metadata": {
        "id": "g8oLxIkVmv5v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Q1: The Filter method in feature selection is a technique that evaluates the relevance of each feature independently of the machine learning model. It works by applying statistical or mathematical metrics to each feature and ranking them based on their individual importance or correlation with the target variable. Features with high scores are considered more relevant and selected for the model.\n",
        "\n",
        "\n",
        "\n",
        "Q2: The Wrapper method in feature selection differs from the Filter method in that it evaluates the performance of the machine learning model with different subsets of features. Instead of considering individual feature relevance, the Wrapper method uses a specific machine learning model as a black box and searches for the best combination of features that maximizes the model's performance, typically through techniques like forward selection, backward elimination, or recursive feature elimination.\n",
        "\n",
        "\n",
        "\n",
        "Q3: Embedded feature selection methods incorporate feature selection as an integral part of the model training process. Some common techniques include:\n",
        "\n",
        "Lasso Regression (L1 regularization): Penalizes the absolute value of feature coefficients, forcing some coefficients to become zero, effectively performing feature selection.\n",
        "Ridge Regression (L2 regularization): Penalizes the square of feature coefficients, which may shrink less relevant feature coefficients towards zero.\n",
        "Tree-based methods (e.g., Random Forest, Gradient Boosting): These methods inherently perform feature selection during the tree-building process by selecting important features to split nodes.\n",
        "\n",
        "\n",
        "\n",
        "Q4: Some drawbacks of using the Filter method for feature selection are:\n",
        "\n",
        "It considers individual feature relevance without considering feature combinations, which may lead to suboptimal selections.\n",
        "It doesn't consider the impact of features on the specific machine learning model's performance, so it may not always select the best features for the chosen model.\n",
        "It may not work well with high-dimensional datasets or datasets with complex feature interactions.\n",
        "\n",
        "\n",
        "\n",
        "Q5: The Filter method is preferred over the Wrapper method in situations where:\n",
        "\n",
        "We have a large dataset with many features, and computational resources are limited.\n",
        "You want a quick and computationally less expensive way to identify potentially relevant features before further refining the selection using more computationally intensive methods.\n",
        "\n",
        "\n",
        "\n",
        "Q6: To choose the most pertinent attributes for the customer churn predictive model using the Filter Method, we can follow these steps:\n",
        "\n",
        "Calculate statistical metrics like correlation, mutual information, or chi-square between each feature and the target variable (customer churn).\n",
        "Rank the features based on their scores obtained from the statistical metrics.\n",
        "Select the top-ranked features that exhibit the highest correlation or information gain with the target variable.\n",
        "\n",
        "\n",
        "\n",
        "Q7: To use the Embedded method for selecting the most relevant features for predicting soccer match outcomes, we can employ techniques like Tree-based methods (e.g., Random Forest, Gradient Boosting). These methods inherently perform feature selection as part of the tree-building process by evaluating feature importance based on how much they contribute to the reduction of impurity (e.g., Gini impurity or entropy) in the decision tree nodes. The higher the feature importance score, the more relevant the feature is for predicting the match outcomes.\n",
        "\n",
        "\n",
        "\n",
        "Q8: To use the Wrapper method for selecting the best set of features for predicting house prices, we can follow these steps:\n",
        "\n",
        "Choose a machine learning model suitable for regression tasks (e.g., Linear Regression, Random Forest Regressor).\n",
        "Start with an empty set of selected features.\n",
        "Iteratively add features to the set based on their impact on the model's performance (e.g., using cross-validation). Continue adding features until the model's performance stops improving or starts to degrade.\n",
        "The final set of selected features represents the best set of predictors for the house price prediction model."
      ],
      "metadata": {
        "id": "R3PRxKBfmi35"
      }
    }
  ]
}