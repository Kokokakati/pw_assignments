{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iaOQ8uCC08Ra"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is Random Forest Regressor?\n",
        "\n",
        "The Random Forest Regressor is an ensemble learning algorithm that belongs to the family of Random Forests. It is used for regression tasks, meaning it is designed to predict continuous outcomes (numeric values) rather than discrete classes. The Random Forest Regressor is an extension of the Random Forest Classifier and is based on the concept of aggregating the predictions of multiple decision trees.\n",
        "\n",
        "\n",
        "\n",
        "Q2. How does Random Forest Regressor reduce the risk of overfitting?\n",
        "\n",
        "Random Forest Regressor reduces the risk of overfitting through the following mechanisms:\n",
        "\n",
        "Bootstrap Sampling: Each decision tree in the ensemble is trained on a random subset of the training data created through bootstrap sampling (sampling with replacement). This introduces diversity among the trees, reducing the risk of overfitting to specific patterns in the training data.\n",
        "Feature Randomization: At each split in a decision tree, a random subset of features is considered for the best split. This randomness further adds diversity and prevents individual trees from becoming too specialized.\n",
        "\n",
        "\n",
        "\n",
        "Q3. How does Random Forest Regressor aggregate the predictions of multiple decision trees?\n",
        "\n",
        "Random Forest Regressor aggregates predictions by averaging the outputs of individual decision trees. For each input instance, predictions from all trees in the ensemble are combined, and the final output is the mean (average) of these predictions. This averaging process helps to reduce variance and produce a more stable and robust prediction.\n",
        "\n",
        "\n",
        "\n",
        "Q4. What are the hyperparameters of Random Forest Regressor?\n",
        "\n",
        "Some common hyperparameters of the Random Forest Regressor include:\n",
        "\n",
        "n_estimators: Number of decision trees in the forest.\n",
        "max_depth: Maximum depth of each decision tree.\n",
        "min_samples_split: Minimum number of samples required to split an internal node.\n",
        "min_samples_leaf: Minimum number of samples required to be at a leaf node.\n",
        "max_features: The number of features to consider when looking for the best split.\n",
        "bootstrap: Whether to use bootstrap sampling for building trees.\n",
        "random_state: Seed for random number generation for reproducibility.\n",
        "\n",
        "\n",
        "\n",
        "Q5. What is the difference between Random Forest Regressor and Decision Tree Regressor?\n",
        "\n",
        "Decision Tree Regressor: Builds a single decision tree that is prone to overfitting if the tree becomes too deep and complex.\n",
        "Random Forest Regressor: An ensemble of multiple decision trees, each trained on a different subset of data and with random feature selection, which helps reduce overfitting and improves generalization.\n",
        "\n",
        "\n",
        "\n",
        "Q6. What are the advantages and disadvantages of Random Forest Regressor?\n",
        "\n",
        "Advantages:\n",
        "\n",
        "Excellent predictive performance, often outperforming individual decision trees.\n",
        "Robust against overfitting due to ensemble averaging and feature randomization.\n",
        "Handles both linear and non-linear relationships in the data.\n",
        "Provides feature importance information.\n",
        "Disadvantages:\n",
        "\n",
        "Increased computational complexity compared to individual decision trees.\n",
        "Lack of interpretability compared to simpler models.\n",
        "May not perform well on small datasets.\n",
        "\n",
        "\n",
        "Q7. What is the output of Random Forest Regressor?\n",
        "\n",
        "The output of a Random Forest Regressor is a continuous numerical prediction for each input instance. For a given set of features, the model predicts a numeric value, which represents the regression estimate.\n",
        "\n",
        "\n",
        "\n",
        "Q8. Can Random Forest Regressor be used for classification tasks?\n",
        "\n",
        "While the Random Forest Regressor is specifically designed for regression tasks, the Random Forest algorithm has a counterpart called the Random Forest Classifier that is intended for classification tasks. The Random Forest Classifier is used to predict categorical outcomes or class labels instead of continuous numeric values."
      ],
      "metadata": {
        "id": "b7BscosJ09hT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "37WcTeA42Es7"
      }
    }
  ]
}