{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is the relationship between polynomial functions and kernel functions in machine learning\n",
        "algorithms?\n",
        "\n",
        "Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?\n",
        "\n",
        "Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?\n",
        "\n",
        "Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter\n",
        "affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works\n",
        "and provide examples of when you might want to increase or decrease its value?\n",
        "\n",
        "Q5. Assignment:\n",
        "\n",
        "1 Import the necessary libraries and load the dataseg\n",
        "\n",
        "2 Split the dataset into training and testing setZ\n",
        "\n",
        "3 Preprocess the data using any technique of your choice (e.g. scaling, normaliMationK\n",
        "\n",
        "4 Create an instance of the SVC classifier and train it on the training data\n",
        "\n",
        "5 use the trained classifier to predict the labels of the testing data\n",
        "\n",
        "6 Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy,\n",
        "precision, recall, F1-score)\n",
        "\n",
        "7 Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to\n",
        "improve its performance\n",
        "\n",
        "8 Train the tuned classifier on the entire dataset\n",
        "\n",
        "9 Save the trained classifier to a file for future use.\n",
        "\n",
        "You can use any dataset of your choice for this assignment, but make sure it is suitable for\n",
        "classification and has a sufficient number of features and samples."
      ],
      "metadata": {
        "id": "QiLoH0lTXycQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. Relationship between polynomial functions and kernel functions in machine learning algorithms:\n",
        "\n",
        "In machine learning, kernel functions play a crucial role in transforming data into a higher-dimensional space without explicitly computing the transformation. Polynomial functions are often used as kernel functions. The relationship lies in the fact that the polynomial kernel is a specific type of kernel function used to create decision boundaries in higher-dimensional spaces, making it suitable for non-linear classification problems."
      ],
      "metadata": {
        "id": "tUuYtgD8YPtb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Q2.\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset (e.g., Iris dataset)\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create an instance of the SVC classifier with a polynomial kernel\n",
        "svm_classifier = SVC(kernel='poly', degree=3)  # 'poly' specifies polynomial kernel, degree is the degree of the polynomial\n",
        "\n",
        "# Train the classifier on the training data\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Use the trained classifier to predict labels for the testing data\n",
        "y_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the performance using accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "baSEBvC2YXfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. Effect of increasing epsilon on the number of support vectors in SVR:\n",
        "\n",
        "In Support Vector Regression (SVR), epsilon (ε) is the margin of tolerance, and it determines the width of the tube within which no penalty is associated with errors. Increasing epsilon may lead to a wider tube, allowing more data points to be considered as support vectors. Therefore, an increase in epsilon might generally increase the number of support vectors.\n",
        "\n",
        "\n",
        "\n",
        "Q4. Effect of parameters on SVR performance:\n",
        "\n",
        "Kernel Function: The choice of kernel function affects how SVR models the underlying relationships in the data. Different types of relationships may be better represented by linear, polynomial, or radial basis function (RBF) kernels.\n",
        "\n",
        "C Parameter: The regularization parameter C controls the trade-off between achieving a smooth fit and minimizing training error. A smaller C allows for a smoother fit, while a larger C emphasizes fitting the training data more closely.\n",
        "\n",
        "Epsilon (ε) Parameter: As mentioned earlier, epsilon controls the width of the tube within which errors are not penalized. A larger epsilon allows for more flexibility in the fitting of the data.\n",
        "\n",
        "Gamma Parameter: For RBF kernel, gamma controls the shape of the decision boundary. Smaller values of gamma result in a broader decision region, and larger values make the decision boundary more tightly fit to the data.\n",
        "\n",
        "The optimal values for these parameters depend on the specific characteristics of the dataset. GridSearchCV or RandomizedSearchCV can be used to find the best combination of hyperparameters through cross-validation."
      ],
      "metadata": {
        "id": "sEDgN39-Ye2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Q5\n",
        "\n",
        "# Import necessary libraries and load the dataset\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import joblib\n",
        "\n",
        "# Load the dataset (choose a suitable dataset)\n",
        "# e.g., iris = datasets.load_iris()\n",
        "# X, y = iris.data, iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Preprocess the data (scaling or normalization)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Create an instance of the SVC classifier\n",
        "svm_classifier = SVC()\n",
        "\n",
        "# Train the classifier on the training data\n",
        "svm_classifier.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Use the trained classifier to predict labels for the testing data\n",
        "y_pred = svm_classifier.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the performance using accuracy (or other metrics)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Tune hyperparameters using GridSearchCV\n",
        "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'poly', 'rbf'], 'gamma': [0.1, 1, 10]}\n",
        "grid_search = GridSearchCV(svm_classifier, param_grid, cv=5)\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Train the tuned classifier on the entire dataset\n",
        "svm_classifier_tuned = SVC(**best_params)\n",
        "svm_classifier_tuned.fit(scaler.transform(X), y)\n",
        "\n",
        "# Save the trained classifier to a file for future use\n",
        "joblib.dump(svm_classifier_tuned, 'svm_classifier_tuned_model.joblib')\n"
      ],
      "metadata": {
        "id": "NMjnf7sjYgfq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}